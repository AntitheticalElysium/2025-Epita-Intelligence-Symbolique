# üß± Noyau Applicatif (`core/`)

Ce r√©pertoire contient les classes et fonctions fondamentales partag√©es par l'ensemble de l'application d'analyse rh√©torique. Il assure la gestion de l'√©tat, l'interaction avec les services externes (LLM, JVM) et d√©finit les r√®gles d'orchestration.

[Retour au README Principal](../README.md)

## Contenu

* **[`shared_state.py`](./shared_state.py)** : D√©finit la classe `RhetoricalAnalysisState`.
    * Repr√©sente l'√©tat mutable de l'analyse (texte brut, t√¢ches assign√©es, arguments identifi√©s, sophismes trouv√©s, belief sets logiques, logs de requ√™tes, r√©ponses des agents, conclusion finale, prochain agent d√©sign√©).
    * Inclut des m√©thodes pour ajouter/modifier ces √©l√©ments et pour s√©rialiser/d√©s√©rialiser l'√©tat (JSON).
    * Poss√®de un logging interne pour tracer les modifications.

* **[`state_manager_plugin.py`](./state_manager_plugin.py)** : D√©finit la classe `StateManagerPlugin`.
    * Un plugin Semantic Kernel qui encapsule une instance de `RhetoricalAnalysisState`.
    * Expose des fonctions natives (`@kernel_function`) aux agents pour lire (`get_current_state_snapshot`) et √©crire (`add_task`, `add_argument`, `add_fallacy`, `add_belief_set`, `log_query_result`, `add_answer`, `set_final_conclusion`, `designate_next_agent`) dans l'√©tat partag√© de mani√®re contr√¥l√©e et tra√ßable.

* **[`strategies.py`](./strategies.py)** : D√©finit les strat√©gies d'orchestration pour `AgentGroupChat` de Semantic Kernel.
    * `SimpleTerminationStrategy` üö¶ : Arr√™te la conversation si `final_conclusion` est pr√©sente dans l'√©tat ou si un nombre maximum de tours (`max_steps`) est atteint.
    * `DelegatingSelectionStrategy` üîÄ : Choisit le prochain agent. Priorise la d√©signation explicite (`_next_agent_designated` dans l'√©tat). Sinon, retourne par d√©faut au `ProjectManagerAgent` apr√®s l'intervention d'un autre agent.

* **[`jvm_setup.py`](./jvm_setup.py)** : G√®re l'interaction avec l'environnement Java. üî•‚òï
    * Contient la logique (`initialize_jvm`) pour :
        * V√©rifier/t√©l√©charger les JARs Tweety requis et leurs binaires natifs dans `libs/`.
        * Trouver un JDK valide (via `JAVA_HOME` ou d√©tection automatique).
        * D√©marrer la JVM via JPype avec le classpath et `java.library.path` corrects.
    * Retourne un statut indiquant si la JVM est pr√™te, essentiel pour l'agent `PropositionalLogicAgent`.

* **[`llm_service.py`](./llm_service.py)** : G√®re la cr√©ation du service LLM. ‚òÅÔ∏è
    * Contient la logique (`create_llm_service`) pour lire la configuration LLM depuis `.env` (OpenAI ou Azure).
    * Cr√©e et retourne l'instance du service (`OpenAIChatCompletion` ou `AzureChatCompletion`) qui sera inject√©e dans le kernel et utilis√©e par les `ChatCompletionAgent`.